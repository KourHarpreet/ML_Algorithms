---
title: "Kmeans"
author: "Harpreet Kour"
date: "July 17, 2018"
output: html_document
---

## - Libraries Required
```{r}
library(ggplot2)
library(dplyr)
library(knitr)
library(broom)
```

## Objective

The Case study involves looking Housing Data. Objective is to draw insights from the data using some ML Techniques. (All the data is dummy data)

## Loading and Understanding Data  
First we read the data and look at vaiorus fields in it. Lets look at the data type of our Raw data. 

```{r}
data = read.csv("E:/50Github/Day1- Kmeans/housing.csv", header=T,stringsAsFactors = F)
options(scipen = 999) #a penalty for scientific display or forced R not to use exponential notation(e+10)

head(data)
#View(data)

summary(data) #We look at summary data to understand spread of data and see if it has any missing values 
sum(is.na(data)) #all NAs are in total_bedrooms column

```

## Plot variables to see the distribution of data

```{r}
qplot(data$housing_median_age, geom="histogram", bins = 30) + xlab("Median House Age in the district")
qplot(data$population, geom="histogram", bins = 40) + xlab("Population Distribution")
qplot(data$households, geom = "histogram", bins = 30)+ xlab("Households")
qplot(data$median_house_value, geom = "histogram", bins = 30)+ xlab("Median House Value")
```


## Normalization: Prepare the dataset for clustering

```{r}
Nor_data <- data[, c(3,6:8)] 
m <- apply(Nor_data,2,mean)
s <- apply(Nor_data,2,sd)
Nor_data <- scale(Nor_data,m,s)

head(Nor_data)
```




## Get appropriate number of clusters - Elblow Plot

```{r}
#Elbow Method for finding the optimal number of clusters
set.seed(123)
# Compute and plot wss for k = 2 to k = 15.

#k.max <- 15
#wss <- sapply(1:k.max, function(k){kmeans(Nor_data, k, nstart=50,iter.max = 15 )$tot.withinss})


wss = (nrow(Nor_data)-1)*sum(apply(Nor_data,2,var))
for (i in 2:15) 
  wss[i] = sum(kmeans(Nor_data,centers=i)$withinss)

  plot(1:15, wss, type="b", pch = 19, xlab="Number of Clusters K",
     ylab="Within groups sum of squares",
     main="Elbow method to look at optimal clusters for Normalized Data") #see where the change is significant
```
This represents the variance within the clusters. It decreases as k increases, but one can notice a bend (or "elbow") right at k=4. This bend indicates that additional clusters beyond the third have little value.


## Clustering

```{r}
set.seed(006)
cluster = kmeans(Nor_data,4) # 4 centers
cluster$centers #to see the centers
data$cluster = cluster$cluster # show clusters

```

## Cluster Summary

```{r}
Summary = data %>% group_by(cluster)%>%
     summarise(MedianAge = mean(housing_median_age),Population = mean(population), value = mean(median_house_value))

kable(Summary)
```

The `tidy` function summarizes on a per-cluster level:

```{r}
tidy(cluster)
```

And as it always does, the `glance` function extracts a single-row summary:

```{r}
glance(cluster)
```


